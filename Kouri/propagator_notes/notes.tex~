\documentclass[amsmath,amssymb,floatfix]{revtex4}

\usepackage{graphicx,psfrag}

\usepackage{amsmath}


\numberwithin{equation}{section}

\newcommand{\comm}[2]{  \left[ \; #1 \; , \; #2 \; \right] }
\newcommand{\eq}[0]{ \; = \; }


\def\bra#1{\mathinner{\langle{#1}|}} 
\def\ket#1{\mathinner{| \, {#1} \: \rangle}} 
\newcommand{\braket}[2]{\langle #1|#2\rangle} 
\newcommand{\threebraket}[3]{\langle {#1}|{ #2} |{#3} \rangle} 
\newcommand{\Integral}[4]{ \int_{#1}^{#2}  \hspace{-2pt} #3 \, d #4 }

\def\Bra#1{\left<#1\right|} 
\def\Ket#1{\left|#1\right>}

\newcommand{\twomat}[4]{ \left( \begin{array}{cc} #1 & #2 \\ #3 & #4  \end{array} \right) }
\newcommand{\twovec}[2]{ \left( \begin{array}{c} #1  \\ #2   \end{array} \right) }

\newcommand{\floor}[0]{ \textrm{fl} }
\newcommand{\ceil}[0]{ \textrm{ceil} }



%\oddsidemargin 0.0in
%\evensidemargin 1.0in
%\textwidth 6.0in
%\headheight 1.0in
%\topmargin 0.5in
\textheight 9.5in
%\footheight 1.0in 



  \renewcommand{\topfraction}{0.9}	% max fraction of floats at top
  \renewcommand{\bottomfraction}{0.8}	% max fraction of floats at bottom
  \setcounter{topnumber}{8}
  \setcounter{bottomnumber}{8}
  \setcounter{totalnumber}{2}     % 2 may work better
  \setcounter{dbltopnumber}{2}    % for 2-column pages
  \renewcommand{\dbltopfraction}{0.9}	% fit big float above 2-col. text
  \renewcommand{\textfraction}{0.07}	% allow minimal text w. figs
  \renewcommand{\floatpagefraction}{0.07}	% require fuller float pages
  \renewcommand{\dblfloatpagefraction}{0.01}	% require fuller float page




\begin{document}


\title{Notes on an acoustic wave propagator}

\author{Donald J. Kouri}
\author{Nicholas Maxwell}
\author{Thomas Markovich}
\affiliation{
Departments of Mathematics and Physics\\
University of Houston\\
Houston, TX 77204-5006\\
kouri@uh.edu, nicholas.maxwell@gmail.com
}


%\date{April 6, 2009}

\begin{abstract}
We present and discuss an operator which propagates solutions of the acoustic wave equation.
\end{abstract}

\maketitle


\section{\label{sec:level1}Introduction\protect}

\noindent
We consider the equation


\begin{equation}
	\ddot{u}(\mathbf{x},t)  = C^2(\mathbf{x}) \, \nabla^2 \, u(\mathbf{x},t),
\end{equation}



%  \frac{\partial^2}{\partial t^2} \, u(\mathbf{x},t)

\noindent
This equation is of the form

\begin{equation}
	 \frac{d^2}{d t^2} \, f(t)  = m^2 f(t),
\end{equation}

\noindent
because $C$ depends only on $\mathbf{x}$. If $f(0) = f_0$, and $\dot{f}(0) = \dot{f}_0$, then this is an initial value problem, and it is standard to derive the particular solution as follows.


\begin{eqnarray}
	 f(t)  =  \cosh{(m \, t)} \,  c_1 + \sinh{(m \, t)} \,  c_2,  \nonumber \\	
	 \dot{f}(t)  =  \sinh{(m \, t)} \,m \,  c_1 + \cosh{(m \, t)} \,m \,  c_2, \nonumber \\	 
	 f(0)  =    c_1 \Rightarrow c_1 = f_0,  \nonumber \\	
	 \dot{f}(0)  = m \,  c_2 \Rightarrow c_2 = \dot{f}_0/m  . \nonumber  \\	 
\end{eqnarray}

\noindent
Thus, writing $z := \sqrt{C^2\nabla^2}$, we assert that the exact solution of equation (I.1) is 

\begin{eqnarray}
	 u(\mathbf{x},t) = \cosh{( t \, z )} \,  A + \sinh{(t \, z)} \, B, \nonumber \\	 
	 \dot{u}(\mathbf{x},t) = \sinh{(t \, z )} \, z\, A + \cosh{(t \, z)} \,z\, B.
\end{eqnarray}

\noindent
And following the same argument,

\begin{eqnarray}
	A = u_0, \nonumber \\	 
	B = z^{-1} \, 	\dot{u}_0.	
\end{eqnarray}

\noindent
Then equation (I.4) becomes

\begin{eqnarray}
	 u(\mathbf{x},t) = \cosh{( t \, z )} \,  u_0 + \sinh{(t \, z)} \, z^{-1} \, 	\dot{u}_0, \nonumber \\	 
	 \dot{u}(\mathbf{x},t) = \sinh{(t \, z )} \, z\, u_0 + \cosh{(t \, z)} \, \dot{u}_0,
\end{eqnarray}

\noindent
which can be rewritten as

\begin{eqnarray}
	 \twovec{u(\mathbf{x},t)}{\dot{u}(\mathbf{x},t)} = \textrm{P}(t; C)  \twovec{u(\mathbf{x},0)}{\dot{u}(\mathbf{x},0)},	 \; \; \; 
	 \textrm{P}(t; C) = \twomat{\cosh{( t \, z )}}{\sinh{(t \, z )} / z}{\sinh{(t \, z )} \, z}{\cosh{( t \, z )}}.
\end{eqnarray}

\section{\label{sec:level2}Investigation\protect}

\noindent
Using the identities 

\begin{eqnarray}
%	\cosh^2{(t)}+\sinh^2{(t)} = \cosh{(2\,t)} \nonumber \\
%	2 \, \sinh{(t)} \cosh{(t)} = \sinh{(2\,t)}, \nonumber \\
	\sinh{(t)}\cosh{(s)}+\cosh{(t)}\sinh{(s)} = \sinh{(t+s)} , \nonumber \\
	\cosh{(t)}\cosh{(s)}+\sinh{(t)}\sinh{(s)} = \cosh{(t+s)} , \nonumber \\
\end{eqnarray}

\noindent
and assuming that $\cosh{( t \, z )}$ commutes with $\sinh{( t \, z )}$, and both commute with $z$ and $z^{-1}$, it is straight-forward to show that 

\begin{eqnarray}
\textrm{P}(t; C) \; \textrm{P}(s; C) = \textrm{P}(t + s; C) ,  \; \; \;  \textrm{P}^n(t; C) = \textrm{P}(n \, t; C).
\end{eqnarray}

\noindent 
We interpret $\cosh{( t \, \sqrt{C^2\nabla^2} )}$ and $\sinh{( t \, \sqrt{C^2\nabla^2} )}$ by their power series expansions. The the Taylor series expansions are given by $\cosh{(x)} = \sum_{n=0}^\infty x^{2n}/(2 n)!$, and $\sinh{(x)} = \sum_{n=0}^\infty x^{2n+1}/(2 n+1)!$, so


\begin{eqnarray}
\cosh{( t \, \sqrt{C^2\nabla^2} )} =  \sum_{n=0}^\infty \frac{t^{2n}}{(2n)!} (C^2\nabla^2)^n
\end{eqnarray}

\begin{eqnarray}
\sinh{( t \, \sqrt{C^2\nabla^2} )} =  \sum_{n=0}^\infty \frac{t^{2n+1}}{(2n+1)!} (C^2\nabla^2)^n \, \sqrt{C^2\nabla^2}.
\end{eqnarray}

\noindent 
Now, it is complicated to evaluate $\sqrt{C^2\nabla^2}$, however, examining the form of $\textrm{P}$, we see that the odd power of $\sqrt{C^2\nabla^2}$ in the expansion is absorbed, and we can write



\begin{equation}
	 \textrm{P}(t; C) = \sum_{n=0}^\infty \twomat{\frac{t^{2n}}{(2n)!}(C^2\nabla^2)^n}{\frac{t^{2n+1}}{(2n+1)!}(C^2\nabla^2)^n}{\frac{t^{2n+1}}{(2n+1)!}(C^2\nabla^2)^{n+1}}{\frac{t^{2n}}{(2n)!}(C^2\nabla^2)^n}
\end{equation}
	 
\begin{equation}
	 \textrm{P}(t; C) = \sum_{n=0}^\infty \frac{t^{2n}(C^2\nabla^2)^n}{(2n+1)!}\twomat{2n+1}{t}{t \, C^2\nabla^2}{2n+1}.
\end{equation}

\noindent 
To a first order,

\begin{eqnarray}
	 \textrm{P}(\tau; C) = \twomat{1}{\tau}{\tau \, C^2\nabla^2}{1} +  ...
\end{eqnarray}

\noindent 
It is standard to write equation (I.1) as 

\begin{eqnarray}
	 \frac{d}{d t} \, \twovec{u(t)}{\dot{u}(t)} =  \twomat{0}{1}{C^2\nabla^2}{0} \twovec{u(t)}{\dot{u}(t)}, 
\end{eqnarray}

\noindent d
then, for small $\tau$,


\begin{equation}
\frac{d}{d t} \, \twovec{u(t)}{\dot{u}(t)} \approx \frac{1}{\tau} \left( \twovec{u(t+\tau)}{\dot{u}(t+\tau)} - \twovec{u(t)}{\dot{u}(t)} \right) \Rightarrow \twovec{u(t+\tau)}{\dot{u}(t+\tau)} \approx \left( \twomat{0}{1}{C^2\nabla^2}{0}  \tau + 1  \right) \twovec{u(t)}{\dot{u}(t)} \nonumber \\
\end{equation}
\begin{equation} 
\twovec{u(t+\tau)}{\dot{u}(t+\tau)} = \twomat{1}{\tau}{\tau \, C^2\nabla^2}{1}  \twovec{u(t)}{\dot{u}(t)}.
\end{equation}

So we can see that truncating the Taylor series of $\textrm{P}$ to the first term is exactly equivalent to Euler's method for the solution of (I.1). 

\section{\label{sec:level3}Application\protect}

Depending on the application, $\dot{u}(t)$ may be unwanted information, so we might try to apply $\textrm{P}$ in such a way that we avoid its computation. If we know that $\dot{u}(0) = 0$, we can take from equation (I.7) that

\begin{equation}
	 u(T) = \cosh{( T \, \sqrt{C^2\nabla^2} )} \; u(0).
\end{equation}

This let's us compute $u(T)$ from $u(0)$, while avoiding $\dot{u}(T)$. We can't then compute $u(T+s)$, as we would again require $\dot{u}(T)$ for that additional step, so we take $T$ as the final step to which we wish to propagate $u$.

Another, less obvious approach is to use the the binomial theorem to show that

\begin{equation}
(\cosh{x})^{2n} =  \frac{2}{4^n} \, \sum _{k=1}^n  \frac{(2n)!}{(n+k)!(n-k)!} \cosh{(2k\,x)} + \frac{(2n)!}{4^n(n!)^2}.
\end{equation}

\noindent
then, for $n = 0$,

\begin{equation}
\cosh{(n \, t \, x)} = 1,
\end{equation}

\noindent
for $n = 1$,

\begin{equation}
\cosh{(n \, t \, x)} = \cosh{( t \, x)},
\end{equation}

\noindent
for $n \ge 2$,

\begin{equation}
\cosh{(n \, t \, x)} = \frac{4^n}{2} (\cosh{(t \, x/2)})^{2n} - \sum_{k=1}^{n-1} \frac{(2n)!}{(n+k)!(n-k)!} \cosh{(k \, t \, x)} - \frac{1}{2} \frac{(2n)!}{(n!)^2}.
\end{equation}


\begin{equation}
\cosh{(n \, t \, x)} = 2^{n-1}  \sum_{k=0}^{n} \frac{n!}{k!(n-k)!} (\cosh{(t \, x)})^{k} - \sum_{k=1}^{n-1} \frac{(2n)!}{(n+k)!(n-k)!} \cosh{(k \, t \, x)} - \frac{1}{2} \frac{(2n)!}{(n!)^2}.
\end{equation}


\section{\label{sec:level3}Boundary effects.\protect}





\section{\label{sec:level3}Taylor Expansion.\protect}


The the Taylor series expansions are given by $\cosh{(x)} = \sum_{n=0}^\infty x^{2n}/(2 n)!$, and $\sinh{(x)} = \sum_{n=0}^\infty x^{2n+1}/(2 n+1)!$, so


\begin{eqnarray}
\cosh{( t \, \sqrt{C^2\nabla^2} )} =  \sum_{n=0}^\infty \frac{t^{2n}}{(2n)!} (C^2\nabla^2)^n
\end{eqnarray}

\begin{eqnarray}
\sinh{( t \, \sqrt{C^2\nabla^2} )} =  \sum_{n=0}^\infty \frac{t^{2n+1}}{(2n+1)!} (C^2\nabla^2)^n \, \sqrt{C^2\nabla^2},
\end{eqnarray}


\begin{equation}
	 \textrm{P}(t; C) = \sum_{n=0}^\infty \twomat{\frac{t^{2n}}{(2n)!}(C^2\nabla^2)^n}{\frac{t^{2n+1}}{(2n+1)!}(C^2\nabla^2)^n}{\frac{t^{2n+1}}{(2n+1)!}(C^2\nabla^2)^{n+1}}{\frac{t^{2n}}{(2n)!}(C^2\nabla^2)^n}
\end{equation}
	 
\begin{equation}
	 \textrm{P}(t; C) = \sum_{n=0}^\infty \frac{t^{2n}(C^2\nabla^2)^n}{(2n)!}\twomat{1}{t/(2n+1)}{t \, C^2\nabla^2/(2n+1)}{1}.
\end{equation}

So, to compute $\twovec{u_1}{v_1} = \textrm{P}(t; C) \twovec{u_0}{v_0}$, truncated to $M$ term in the expansion, we can generate the sequences $(U_n)_{n=0}^{M+1}$ and $(V_n)_{n=0}^{M}$, as

\begin{eqnarray}
	 U_0 = u_0, \; \; U_n = t^2 \, C^2\nabla^2 \, U_{n-1} / {(4n^2-2n)},\\
  	 V_0 = v_0, \; \; V_n = t^2 \, C^2\nabla^2 \, V_{n-1} / {(4n^2-2n)}
\end{eqnarray}

\begin{eqnarray}
	 u_1 = \sum_{n=0}^M \, U_n +  t \, V_n/(2n+1),\\
	 v_1 = \sum_{n=0}^M \, \frac{1}{t} \, (4n^2+6n+2)U_{n+1}/(2n+1) + V_n,\\	 
\end{eqnarray}

\section{\label{sec:level3}Hermite Expansion.\protect}

\noindent using the expansion, 


\begin{equation}
	\exp{(-i \, t \, x)} = \sum_{m=0}^{\infty} \frac{(-i \, t \, \lambda)^{m}}{m! \, 2^{m}} \exp{\left(-\frac{( t \, \lambda  )^2}{4}\right)} H_m(x/\lambda),
\end{equation}

\begin{equation}
	\cosh{( t \, x)} = \sum_{m=0}^{\infty} c_m(t \, \lambda) H_{2m}(x/\lambda), \, \, c_m(t \, \lambda) =  \frac{(t \, \lambda)^{2m}}{(2m)! \, 4^{m}} \exp{\left(\frac{(t \, \lambda )^2}{4}\right)} .
\end{equation}

Then, we can use the recurrence relation


\begin{equation}
	H_{2m}(x) = (4x^2 -8m+6)H_{2m-2}(x)-8(m-1)(2m-3)H_{2m-4}(x),
\end{equation}
\begin{equation}
	 H_{0}(x) = 1, \, H_{2}(x) = 4x^2-2. \nonumber
\end{equation}



\section{\label{sec:level3}Laguerre Expansion.\protect}

\noindent 
We wish to expand $\exp{(i \, t \, x)}$ into a power series,

\begin{equation}
e^{i \, t \, x} = \sum _{n=0}^\infty \tilde{c}_n^{(\alpha)}(t) L_n^{(\alpha)}(x),
\end{equation}

\noindent where $L_n^{(\alpha)}$ is the $n^{th}$ generalized Laguerre polynomial, which have $\alpha$ as a parameter. If $\alpha = \pm \frac{1}{2}$, then (IV.1) becomes a Hermite polynomial expansion. It is non-trivial to show that


\begin{equation}
\tilde{c}_n^{(\alpha)}(t) = (-i \, t)^n (1-i \, t)^{-1-n-\alpha},
\end{equation}

\noindent 
which we've been unable to simplify to a more enlightening form.



Then, the expansions are 
% for $\cosh{(t \, x)}$ is

\begin{equation}
\cosh{(t \, x)} = \sum _{n=0}^\infty {c}_n^{(\alpha)}(t) \frac{1}{2} \left( L_n^{(\alpha)}(x) + L_n^{(\alpha)}(-x) \right),
\end{equation}

\begin{equation}
\sinh{(t \, x)} = \sum _{n=0}^\infty {c}_n^{(\alpha)}(t) \frac{1}{2} \left( L_n^{(\alpha)}(x) - L_n^{(\alpha)}(-x) \right),
\end{equation}


\noindent
where  ${c}_n^{(\alpha)}(t) =   \tilde{c}_n^{(\alpha)}(i \, t) =  (t)^n (1+ \, t)^{-1-n-\alpha}$.

	Using that

\begin{equation}
	L_n^{(\alpha)}(x)= \sum_{m=0}^n \frac{(-x)^m }{m!}  \binom {n+\alpha} {n-m},
\end{equation}


%\begin{equation}
%\cosh{(t \, x)} = \sum _{n=0}^\infty  \sum_{m=0}^{\floor{(n/2)}} \frac{{c}_n^{(\alpha)}(t)}{(2m)!}  \binom {n+\alpha} {n-2m} x^{2m}
%\end{equation}

%\begin{equation}
%\sinh{(t \, x)} = \sum _{n=0}^\infty  \sum_{m=0}^{\floor{(n/2)}} \frac{{c}_n^{(\alpha)}(t)}{(2m+1)!}  \binom {n+\alpha} {n-2m+1} x^{2m+1}
%\end{equation}

\noindent
we truncate these expansions to $2N$ terms and switch the sums, 



\begin{equation}
\cosh{(t \, x)} \approx  \sum_{m=0}^{N}  \frac{a_m^{(\alpha,N)}(t)  }{(2m)!}   x^{2m}, \, \, a_m^{(\alpha,N)}(t)  =  \sum _{n=2m}^{2N}  {c}_n^{(\alpha)}(t)  \binom {n+\alpha} {n-2m}
\end{equation}

\begin{equation}
\sinh{(t \, x)} \approx  \sum_{m=0}^{N}  \frac{b_m^{(\alpha,N)}(t)  }{(2m+1)!}   x^{2m+1}, \, \, b_m^{(\alpha,N)}(t) =  \sum _{n=2m+1}^{2N}  {c}_n^{(\alpha)}(t)  \binom {n+\alpha} {n-2m-1}.
\end{equation}

With $\binom{z}{n} = \prod_{k=1}^{n} \frac{z-n+k}{k}$,

\begin{equation}
	a_m^{(\alpha,N)}(t)  =  \sum _{n=2m}^{2N}  \exp \left( n \log t - (+1+n+\alpha) \log (1+t) + \sum_{k=1}^{n-2m} \left( \log( k+\alpha +2m ) - \log{k} \right)   \right)
\end{equation}


\begin{equation}
	b_m^{(\alpha,N)}(t)  =  \sum _{n=2m+1}^{2N}  \exp \left( n \log t - (+1+n+\alpha) \log (1+t) + \sum_{k=1}^{n-2m-1} \left( \log( k+\alpha +2m+1 ) - \log{k} \right)   \right)
\end{equation}





\begin{thebibliography}{14}

\bibitem{1}  Bodmann, Hoffman, Kouri, Papadakis,  \textit{Hermite Distributed Approximating Functionals as Almost-Ideal Low-Pass Filters} , (Sampling Theory in Signal And Image Processing, 2008 Vol. 7, No. 1)

\end{thebibliography}




\end{document}
